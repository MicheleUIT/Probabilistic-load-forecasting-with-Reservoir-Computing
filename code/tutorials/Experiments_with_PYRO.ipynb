{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "import pyro.distributions.constraints as constraints\n",
    "import numpy as np\n",
    "\n",
    "from pyro.optim import Adam\n",
    "from pyro.infer import SVI, Trace_ELBO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PYRO\n",
    "[Getting started page](https://pyro.ai/examples/index.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "Given some observations $x$, latent RV $z$, and paramenter $\\theta$, the link between them is called (probabilistic) **model**, with pdf $$p_\\theta(x,z)=p_\\theta(x|z)p_\\theta(z)$$\n",
    "where $p_\\theta(x|z)$ is the *likelihood*, $p_\\theta(z)$ is the *prior*.\n",
    "\n",
    "Things that we may be interested in are:\n",
    "- inferring something about $z$ from data, i.e., the *posterior* $p_\\theta(z|x)=\\frac{p_\\theta(x,z)}{\\int dz p_\\theta(x,z)}$\n",
    "- how well the model describes data, i.e., the *marginal* $p_\\theta(x)=\\int dz p_\\theta(x,z)$\n",
    "- predict new data from the *posterior predictive distribution* $p_\\theta(x'|x)=\\int dz p_\\theta(x'|z)p_\\theta(z|x)$\n",
    "- learning the parameter $\\theta$ that best explain data, $\\theta_\\text{max}=\\argmax_\\theta p_\\theta(x)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data $x$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create some data with 6 observed heads and 4 observed tails\n",
    "data = []\n",
    "for _ in range(6):\n",
    "    data.append(torch.tensor(1.0))\n",
    "for _ in range(4):\n",
    "    data.append(torch.tensor(0.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we define a model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.50.0 (0)\n -->\n<!-- Pages: 1 -->\n<svg width=\"810pt\" height=\"253pt\"\n viewBox=\"0.00 0.00 809.69 253.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 249)\">\n<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-249 805.69,-249 805.69,4 -4,4\"/>\n<!-- latent_fairness -->\n<g id=\"node1\" class=\"node\">\n<title>latent_fairness</title>\n<ellipse fill=\"white\" stroke=\"black\" cx=\"400.85\" cy=\"-158.5\" rx=\"61.99\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"400.85\" y=\"-154.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">latent_fairness</text>\n</g>\n<!-- obs_0 -->\n<g id=\"node2\" class=\"node\">\n<title>obs_0</title>\n<ellipse fill=\"grey\" stroke=\"black\" cx=\"31.85\" cy=\"-18\" rx=\"31.7\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"31.85\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">obs_0</text>\n</g>\n<!-- latent_fairness&#45;&gt;obs_0 -->\n<g id=\"edge1\" class=\"edge\">\n<title>latent_fairness&#45;&gt;obs_0</title>\n<path fill=\"none\" stroke=\"black\" d=\"M363.29,-144.12C302.15,-122.21 177.43,-77.03 72.85,-36 70.61,-35.12 68.3,-34.2 65.99,-33.27\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"67.08,-29.94 56.5,-29.4 64.44,-36.42 67.08,-29.94\"/>\n</g>\n<!-- obs_1 -->\n<g id=\"node3\" class=\"node\">\n<title>obs_1</title>\n<ellipse fill=\"grey\" stroke=\"black\" cx=\"113.85\" cy=\"-18\" rx=\"31.7\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"113.85\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">obs_1</text>\n</g>\n<!-- latent_fairness&#45;&gt;obs_1 -->\n<g id=\"edge2\" class=\"edge\">\n<title>latent_fairness&#45;&gt;obs_1</title>\n<path fill=\"none\" stroke=\"black\" d=\"M370.4,-142.81C315.99,-116.55 202.52,-61.79 146.53,-34.77\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"147.94,-31.57 137.41,-30.37 144.9,-37.87 147.94,-31.57\"/>\n</g>\n<!-- obs_2 -->\n<g id=\"node4\" class=\"node\">\n<title>obs_2</title>\n<ellipse fill=\"grey\" stroke=\"black\" cx=\"195.85\" cy=\"-18\" rx=\"31.7\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"195.85\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">obs_2</text>\n</g>\n<!-- latent_fairness&#45;&gt;obs_2 -->\n<g id=\"edge3\" class=\"edge\">\n<title>latent_fairness&#45;&gt;obs_2</title>\n<path fill=\"none\" stroke=\"black\" d=\"M377.33,-141.61C339.31,-115.93 264.52,-65.39 223.82,-37.9\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"225.69,-34.94 215.45,-32.24 221.77,-40.74 225.69,-34.94\"/>\n</g>\n<!-- obs_3 -->\n<g id=\"node5\" class=\"node\">\n<title>obs_3</title>\n<ellipse fill=\"grey\" stroke=\"black\" cx=\"277.85\" cy=\"-18\" rx=\"31.7\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"277.85\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">obs_3</text>\n</g>\n<!-- latent_fairness&#45;&gt;obs_3 -->\n<g id=\"edge4\" class=\"edge\">\n<title>latent_fairness&#45;&gt;obs_3</title>\n<path fill=\"none\" stroke=\"black\" d=\"M386.01,-140.79C364.14,-116.17 323.19,-70.05 298.43,-42.17\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"300.86,-39.64 291.6,-34.49 295.63,-44.29 300.86,-39.64\"/>\n</g>\n<!-- obs_4 -->\n<g id=\"node6\" class=\"node\">\n<title>obs_4</title>\n<ellipse fill=\"grey\" stroke=\"black\" cx=\"359.85\" cy=\"-18\" rx=\"31.7\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"359.85\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">obs_4</text>\n</g>\n<!-- latent_fairness&#45;&gt;obs_4 -->\n<g id=\"edge5\" class=\"edge\">\n<title>latent_fairness&#45;&gt;obs_4</title>\n<path fill=\"none\" stroke=\"black\" d=\"M395.82,-140.52C388.84,-116.95 376.15,-74.06 367.86,-46.06\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"371.11,-44.72 364.92,-36.12 364.4,-46.7 371.11,-44.72\"/>\n</g>\n<!-- obs_5 -->\n<g id=\"node7\" class=\"node\">\n<title>obs_5</title>\n<ellipse fill=\"grey\" stroke=\"black\" cx=\"441.85\" cy=\"-18\" rx=\"31.7\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"441.85\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">obs_5</text>\n</g>\n<!-- latent_fairness&#45;&gt;obs_5 -->\n<g id=\"edge6\" class=\"edge\">\n<title>latent_fairness&#45;&gt;obs_5</title>\n<path fill=\"none\" stroke=\"black\" d=\"M405.87,-140.52C412.85,-116.95 425.55,-74.06 433.84,-46.06\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"437.3,-46.7 436.78,-36.12 430.58,-44.72 437.3,-46.7\"/>\n</g>\n<!-- obs_6 -->\n<g id=\"node8\" class=\"node\">\n<title>obs_6</title>\n<ellipse fill=\"grey\" stroke=\"black\" cx=\"523.85\" cy=\"-18\" rx=\"31.7\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"523.85\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">obs_6</text>\n</g>\n<!-- latent_fairness&#45;&gt;obs_6 -->\n<g id=\"edge7\" class=\"edge\">\n<title>latent_fairness&#45;&gt;obs_6</title>\n<path fill=\"none\" stroke=\"black\" d=\"M414.06,-140.77C428.03,-123.28 450.9,-95.2 471.85,-72 481.25,-61.58 492.07,-50.44 501.39,-41.07\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"503.88,-43.53 508.49,-33.99 498.94,-38.57 503.88,-43.53\"/>\n</g>\n<!-- obs_7 -->\n<g id=\"node9\" class=\"node\">\n<title>obs_7</title>\n<ellipse fill=\"grey\" stroke=\"black\" cx=\"605.85\" cy=\"-18\" rx=\"31.7\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"605.85\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">obs_7</text>\n</g>\n<!-- latent_fairness&#45;&gt;obs_7 -->\n<g id=\"edge8\" class=\"edge\">\n<title>latent_fairness&#45;&gt;obs_7</title>\n<path fill=\"none\" stroke=\"black\" d=\"M411.14,-140.51C423.45,-121.47 445.69,-90.82 471.85,-72 507.83,-46.12 523.71,-52.49 564.85,-36 566.94,-35.16 569.09,-34.29 571.25,-33.41\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"572.81,-36.56 580.73,-29.52 570.15,-30.08 572.81,-36.56\"/>\n</g>\n<!-- obs_8 -->\n<g id=\"node10\" class=\"node\">\n<title>obs_8</title>\n<ellipse fill=\"grey\" stroke=\"black\" cx=\"687.85\" cy=\"-18\" rx=\"31.7\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"687.85\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">obs_8</text>\n</g>\n<!-- latent_fairness&#45;&gt;obs_8 -->\n<g id=\"edge9\" class=\"edge\">\n<title>latent_fairness&#45;&gt;obs_8</title>\n<path fill=\"none\" stroke=\"black\" d=\"M410.19,-140.4C421.9,-120.66 443.88,-88.77 471.85,-72 539.94,-31.15 570.94,-59.31 646.85,-36 649.3,-35.25 651.8,-34.4 654.31,-33.51\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"655.76,-36.7 663.85,-29.84 653.26,-30.16 655.76,-36.7\"/>\n</g>\n<!-- obs_9 -->\n<g id=\"node11\" class=\"node\">\n<title>obs_9</title>\n<ellipse fill=\"grey\" stroke=\"black\" cx=\"769.85\" cy=\"-18\" rx=\"31.7\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"769.85\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">obs_9</text>\n</g>\n<!-- latent_fairness&#45;&gt;obs_9 -->\n<g id=\"edge10\" class=\"edge\">\n<title>latent_fairness&#45;&gt;obs_9</title>\n<path fill=\"none\" stroke=\"black\" d=\"M409.8,-140.44C421.29,-120.43 443.2,-87.97 471.85,-72 572.59,-15.85 617.57,-66.33 728.85,-36 731.32,-35.33 733.84,-34.54 736.36,-33.68\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"737.78,-36.89 745.92,-30.11 735.33,-30.33 737.78,-36.89\"/>\n</g>\n<!-- distribution_description_node -->\n<g id=\"node12\" class=\"node\">\n<title>distribution_description_node</title>\n<text text-anchor=\"start\" x=\"488.35\" y=\"-229.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">latent_fairness ~ Beta</text>\n<text text-anchor=\"start\" x=\"488.35\" y=\"-214.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">obs_0 ~ Bernoulli</text>\n<text text-anchor=\"start\" x=\"488.35\" y=\"-199.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">obs_1 ~ Bernoulli</text>\n<text text-anchor=\"start\" x=\"488.35\" y=\"-184.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">obs_2 ~ Bernoulli</text>\n<text text-anchor=\"start\" x=\"488.35\" y=\"-169.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">obs_3 ~ Bernoulli</text>\n<text text-anchor=\"start\" x=\"488.35\" y=\"-154.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">obs_4 ~ Bernoulli</text>\n<text text-anchor=\"start\" x=\"488.35\" y=\"-139.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">obs_5 ~ Bernoulli</text>\n<text text-anchor=\"start\" x=\"488.35\" y=\"-124.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">obs_6 ~ Bernoulli</text>\n<text text-anchor=\"start\" x=\"488.35\" y=\"-109.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">obs_7 ~ Bernoulli</text>\n<text text-anchor=\"start\" x=\"488.35\" y=\"-94.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">obs_8 ~ Bernoulli</text>\n<text text-anchor=\"start\" x=\"488.35\" y=\"-79.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">obs_9 ~ Bernoulli</text>\n</g>\n</g>\n</svg>\n",
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x297a3b5ed60>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def model(data):\n",
    "    # define the hyperparameters that control the Beta prior\n",
    "    alpha0 = torch.tensor(10.0)\n",
    "    beta0 = torch.tensor(10.0)\n",
    "    # sample f from the Beta prior\n",
    "    f = pyro.sample(\"latent_fairness\", dist.Beta(alpha0, beta0))\n",
    "    # loop over the observed data\n",
    "    for i in range(len(data)):\n",
    "        # observe datapoint i using the Bernoulli\n",
    "        # likelihood Bernoulli(f)\n",
    "        pyro.sample(\"obs_{}\".format(i), dist.Bernoulli(f), obs=data[i])\n",
    "\n",
    "pyro.render_model(model, model_args=(torch.tensor(data),), render_distributions=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guide\n",
    "A **guide** is the variational distribution $q_\\phi(z)$ that approximates the posterior $p_\\theta(z|x)$. It does not contain data, unlike the model, but it must have all the latent variables that the model has (the correspondence is guaranteed by their **names**)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def guide(data):\n",
    "    # register the two variational parameters with Pyro.\n",
    "    alpha_q = pyro.param(\"alpha_q\", torch.tensor(15.0),\n",
    "                         constraint=constraints.positive)\n",
    "    beta_q = pyro.param(\"beta_q\", torch.tensor(15.0),\n",
    "                        constraint=constraints.positive)\n",
    "    # sample latent_fairness from the distribution Beta(alpha_q, beta_q)\n",
    "    pyro.sample(\"latent_fairness\", dist.Beta(alpha_q, beta_q))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the guide above doesn't have the \"obs\" RV."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVI\n",
    "In order to do variational inference PYRO uses SVI class, which needs: a model, a guide and an optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 7.032658100128174\n",
      "Loss: 7.071733474731445\n",
      "Loss: 7.062897801399231\n",
      "Loss: 7.093270421028137\n",
      "Loss: 7.069697618484497\n",
      "Loss: 7.077534437179565\n",
      "Loss: 7.073229670524597\n",
      "Loss: 7.075173497200012\n",
      "Loss: 7.040586233139038\n",
      "Loss: 7.074746489524841\n"
     ]
    }
   ],
   "source": [
    "# set up the optimizer\n",
    "adam_params = {\"lr\": 0.0005, \"betas\": (0.90, 0.999)}\n",
    "optimizer = Adam(adam_params)\n",
    "\n",
    "# setup the inference algorithm\n",
    "svi = SVI(model, guide, optimizer, loss=Trace_ELBO())\n",
    "\n",
    "n_steps = 5000\n",
    "losses = []\n",
    "# do gradient steps\n",
    "for step in range(n_steps):\n",
    "    loss = svi.step(data) # step ensures that data is passed to both model and guide\n",
    "    losses.append(loss)\n",
    "\n",
    "    if step % 500 == 0:\n",
    "        print(f\"Loss: {loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What did we learn?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Based on the data and our prior belief, the fairness of the coin is 0.537 +- 0.089\n"
     ]
    }
   ],
   "source": [
    "# grab the learned variational parameters\n",
    "alpha_q = pyro.param(\"alpha_q\").item()\n",
    "beta_q = pyro.param(\"beta_q\").item()\n",
    "\n",
    "# here we use some facts about the Beta distribution\n",
    "# compute the inferred mean of the coin's fairness\n",
    "inferred_mean = alpha_q / (alpha_q + beta_q)\n",
    "# compute inferred standard deviation\n",
    "factor = beta_q / (alpha_q * (1.0 + alpha_q + beta_q))\n",
    "inferred_std = inferred_mean * math.sqrt(factor)\n",
    "\n",
    "print(\"\\nBased on the data and our prior belief, the fairness \" +\n",
    "      \"of the coin is %.3f +- %.3f\" % (inferred_mean, inferred_std))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this simple scenario we can analytically compute the true posterior using Bayes' theorem:\n",
    "- The latent variable $z$ is defined within the model and its prior is a Beta distribution, i.e., $$p(z;\\alpha,\\beta)=\\frac{1}{B(\\alpha,\\beta)}z^{\\alpha-1}(1-z)^{\\beta-1},$$ where $B(\\alpha,\\beta)$ is the normalizing constant.\n",
    "- The likelihood is defined within the model as well and it's a Bernoulli, $p(x|z)=z^x(1-z)^{1-x}$.\n",
    "\n",
    "So the true posterior is \n",
    "$$\n",
    "\\begin{align}\n",
    "    p(z|x) &\\propto \\prod_{i=1}^N \\, p(z;\\alpha,\\beta)p(x_i|z) \\propto \\\\\n",
    "        &\\propto \\prod_i \\, z^{\\alpha-1}(1-z)^{\\beta-1}z^x_i(1-z)^{1-x_i} = \\\\\n",
    "        &= z^{\\alpha-1+\\sum_i x_i}(1-z)^{N+\\beta-1-\\sum_i x_i} \n",
    "\\end{align}\n",
    "$$\n",
    "which is again a Beta distribution (so our guide is not an _approximation_ of the true distribution, that explains why the loss doesn't really decrease much) with coefficients\n",
    "$$\n",
    "    \\tilde{\\alpha} = \\alpha +\\sum_{i=1}^N\\,x_i = 10 + 6 = 16\n",
    "$$\n",
    "$$\n",
    "    \\tilde{\\beta} = N + \\beta - \\sum_{i=1}^N\\,x_i = 10 + 10 - 6 = 14\n",
    "$$\n",
    "which give\n",
    "$$\n",
    "    \\text{mean} = \\frac{\\tilde{\\alpha}}{\\tilde{\\alpha}+\\tilde{\\beta}} = \\frac{16}{30} = 0.5\\bar{3}\n",
    "$$\n",
    "$$\n",
    "    \\text{std} = \\frac{1}{\\tilde{\\alpha}+\\tilde{\\beta}}\\sqrt{\\frac{\\tilde{\\alpha}\\tilde{\\beta}}{\\tilde{\\alpha}+\\tilde{\\beta}+1}} \\simeq 0.09\n",
    "$$\n",
    "They are compatible with what found with SVI\n",
    "$$\n",
    "    \\lambda = \\frac{|0.5\\bar{3}-0.537|}{\\sqrt{0.089^2+0.09^2}} \\simeq 0.03 < 1.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(6.)\n"
     ]
    }
   ],
   "source": [
    "# sum of x\n",
    "sum = torch.tensor(data).sum()\n",
    "print(sum)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('uncertainty')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "60557ac213c4f904567501e30163cbfc56b9c76312e53cab0b1cef6c972a9f33"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
